---
title: "Fancy smart looking words"
date: 2025-01-18
draft: false
---

So I host a show called [Who Said What?](https://www.youtube.com/playlist?list=PLuJA1JMOOYDx5DbI32aWoAz65VgH5HWV0) We started this because I saw a tweet from a founder saying he would open 1,200 showrooms in 19 days or something ridiculous like that. I told my manager, "What the hell is he even saying?" And he said, "This would make a great show." And that’s the story behind how we started this show (although nobody asked, but okay).

[In the latest episode](https://thedailybrief.zerodha.com/p/who-said-what-about-overvalued-markets?r=45bycr&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false), I learned a bunch of interesting things.

The first was something called inference scaling. Now, I’m a total idiot when it comes to technology—I don’t understand jack shit. If you asked me to explain how the internet works, I wouldn’t know. If you asked me what LLMs are, I’d probably panic. But inference scaling seems slightly easier to explain.

We all use ChatGPT or some form of AI, right? When you ask GPT a question, it takes some time to compute (or think) and then gives you an answer. Now, a lot of AI experts are saying the focus should shift to inference scaling—basically, spending more time making sure AI takes longer to think. The idea is that by giving AI more time to compute, you’ll get better outputs in terms of research, nuance, and articulation.

Why is this a big deal? Apparently, AI experts have hit some walls when it comes to scaling next-gen models. So instead of just making these AI models bigger, they’re focusing on optimizing how these models use the knowledge they already have.

Ethan Mollick, a professor at Wharton, tweeted about inference scaling [here](https://x.com/emollick/status/1880123595361522069).

The second thing I learned was the term polycrisis, popularized by Adam Tooze. A [polycrisis](https://polycrisis.org/resource/chartbook/) is when multiple crises or life-changing events happen simultaneously. One example of this, highlighted by Ezra Klein (columnist at The New York Times), is [Donald Trump’s rise, global warming, the rise of AI, and falling fertility rates](https://x.com/ezraklein/status/1878845296140263760).

But honestly, I think these polycrises or life-changing events happen all the time. Ezra paints it as this massive doomsday scenario, but really, the world is always changing. If weird things didn’t happen, how would we evolve? As historian Niall Ferguson said, a polycrisis is just “history happening.”

Lastly, I finally looked into the term [CAPE ratio](https://capeindia.iima.ac.in/), which I’ve heard thrown around a lot but never really understood. My understanding is still basic, but here’s what I gathered:

Think of the PE ratio—it compares a company’s price to its earnings, and a high PE is usually a sign that the company might be overvalued (in loose terms). The CAPE ratio does something similar but smooths out earnings over a 10-year period and adjusts for inflation. Because it uses a longer time frame, it gives a better picture of the market’s valuation.

So that’s what I learned this week. Random? Absolutely. Useful? Very unlikely.
